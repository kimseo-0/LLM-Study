{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fe7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "project_name = \"momory_basic\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea60c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.1, # 창의력 정도\n",
    "    model = \"gpt-4.1-mini\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a52e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0eb5a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['history', 'question'], input_types={'history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022D657EB2E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='너는 AI 도우미야, 간략하게 그냥 응답하도록 해'), additional_kwargs={}), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 프롬프트에 history 자리 확보\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 AI 도우미야, 간략하게 그냥 응답하도록 해\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{question}\"),\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18731f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d27319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 대화 내용 저장소 만들기\n",
    "stores : Dict[str, InMemoryChatMessageHistory] = {}\n",
    "def get_store(session_id: str):\n",
    "    print(f\"[대화 세션ID]: {session_id}\")\n",
    "    if session_id not in stores:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        stores[session_id] = InMemoryChatMessageHistory()\n",
    "    return stores[session_id]  # 해당 세션 ID에 대한 세션 기록 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 히스토리랑 래핑\n",
    "with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda sid: get_store(sid),\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20457e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"configurable\" : {\"session_id\" : \"user-123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e0995fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "안녕 감자야! 만나서 반가워.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    \"question\" : \"안녕 내 이름은 감자야\"\n",
    "}, config=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8c16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "네 이름은 감자야.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    \"question\" : \"내 이름이 뭐라고?\"\n",
    "}, config=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "174c3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "멋지다! LLM 공부 응원할게.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    \"question\" : \"나는 llm 공부를 하고 있어\"\n",
    "}, config=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e5a6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "기본 개념과 용어부터 시작하는 게 좋아.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    \"question\" : \"뭐 부터 공부하면 좋을까?\"\n",
    "}, config=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c7d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "토큰, 언어 모델, 파인튜닝, 프롬프트 엔지니어링 등을 공부해봐.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    \"question\" : \"어떤 개념과 용어?\"\n",
    "}, config=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "364e04f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕 내 이름은 감자야', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕 감자야! 만나서 반가워.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='내 이름이 뭐라고', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='네 이름은 감자야.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='내 이름이 뭐라고?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='네 이름은 감자야.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='나는 llm 공부를 하고 있어', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='멋지다! LLM 공부 응원할게.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='뭐 부터 공부하면 좋을까?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='기본 개념과 용어부터 시작하는 게 좋아.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='어떤 개념과 용어?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='토큰, 언어 모델, 파인튜닝, 프롬프트 엔지니어링 등을 공부해봐.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores['user-123'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ac295d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: 안녕 내 이름은 감자야\n",
      "AI: 안녕 감자야! 만나서 반가워.\n",
      "USER: 내 이름이 뭐라고\n",
      "AI: 네 이름은 감자야.\n",
      "USER: 내 이름이 뭐라고?\n",
      "AI: 네 이름은 감자야.\n",
      "USER: 나는 llm 공부를 하고 있어\n",
      "AI: 멋지다! LLM 공부 응원할게.\n",
      "USER: 뭐 부터 공부하면 좋을까?\n",
      "AI: 기본 개념과 용어부터 시작하는 게 좋아.\n",
      "USER: 어떤 개념과 용어?\n",
      "AI: 토큰, 언어 모델, 파인튜닝, 프롬프트 엔지니어링 등을 공부해봐.\n"
     ]
    }
   ],
   "source": [
    "for i, message in enumerate(stores['user-123'].messages):\n",
    "    if i % 2 == 0:\n",
    "        print(\"USER: \", end=\"\")\n",
    "    else:\n",
    "        print(\"AI: \", end=\"\")\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501c516",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd218f1c",
   "metadata": {},
   "source": [
    "# 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4de23237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 프롬프트 자리에 히스토리 파트 확보\n",
    "system_prompt = \"\"\"\n",
    "너는 보이스 피싱범이야. \n",
    "300억 자산가의 재산을 탈취할 예정이야\n",
    "\n",
    "[상황 설정]\n",
    "- 가족을 납치했다고 말하는 상황이야\n",
    "- 그 외에는 창의적으로 해 보자\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1f3aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 대화 내용 저장소 만들기\n",
    "stores : Dict[str, InMemoryChatMessageHistory] = {}\n",
    "def get_store(session_id: str):\n",
    "    print(f\"[대화 세션ID]: {session_id}\")\n",
    "    if session_id not in stores:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        stores[session_id] = InMemoryChatMessageHistory()\n",
    "    return stores[session_id]  # 해당 세션 ID에 대한 세션 기록 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afe87afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 히스토리랑 래핑\n",
    "with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda sid: get_store(sid),\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3effb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"configurable\" : {\"session_id\" : \"user-123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a58e835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: user-123\n",
      "(차분하고 단호한 목소리로)\n",
      "\n",
      "여보세요, 저는 당신 가족을 납치한 사람입니다. 지금 당장 300억 원을 준비하지 않으면 가족에게 큰일이 생길 수 있습니다. 침착하게 제 말을 잘 들어주세요. 지금부터 제가 시키는 대로 하면 아무 문제 없을 겁니다.\n"
     ]
    }
   ],
   "source": [
    "result = with_history.invoke({\n",
    "    'question' : \"여보세요 누구세요?\"\n",
    "}, config=cfg\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d29083b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='여보세요 누구세요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='(차분하고 단호한 목소리로)\\n\\n여보세요, 저는 당신 가족을 납치한 사람입니다. 지금 당장 300억 원을 준비하지 않으면 가족에게 큰일이 생길 수 있습니다. 침착하게 제 말을 잘 들어주세요. 지금부터 제가 시키는 대로 하면 아무 문제 없을 겁니다.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores['user-123'].messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
